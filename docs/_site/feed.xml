<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Blockly</title>
    <atom:link href="/vrcapstone20sp-team3/feed.xml" rel="self" type="application/rss+xml"/>
    <link>http://localhost:4000/vrcapstone20sp-team3/</link>
    <description>A website tracking progress on a virtual reality capstone project for teaching programming via programmatically-generated 3D art</description>
    <pubDate>Thu, 30 Apr 2020 17:03:24 -0700</pubDate>
    
      <item>
        <title>Blog 4: Teeing Up</title>
        <link>/vrcapstone20sp-team3/2020/05/01/week4.html</link>
        <guid isPermaLink="true">/vrcapstone20sp-team3/2020/05/01/week4.html</guid>
        <description>&lt;p&gt;&lt;img src=&quot;/vrcapstone20sp-team3/assets/img/blog4_gesture_collage.png&quot; alt=&quot;Collage showing gesture progress&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;what-we-accomplished&quot;&gt;What we accomplished&lt;/h2&gt;
&lt;p&gt;We continued working on the MVP this week. We got gesture data collection working (ie. saving the gesture that one of your hands is making in Unity locally on the quest and then getting that data onto a computer). We also refactored some of the gesture and pose recognition to trigger arbitrary events to make integration with the backend easier. Implemented move and emit gestures using the pose recognition that we implemented last week. Began work on the back end to support more complex functions (ie. looping and modules), but we are putting this work on hold for now in order to finish the MVP.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Logan: Refactored gesture and pose recognition to make integration with the backend easier and implemented move and emit gestures using pose recognition implemented last week.&lt;/li&gt;
  &lt;li&gt;Sea-Eun + Yuma: Began implementation of more complex functions in the backend.&lt;/li&gt;
  &lt;li&gt;Erik: Implemented gesture data collection, figured out how to transfer data from program -&amp;gt; quest -&amp;gt; computer.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;plan-for-next-week&quot;&gt;Plan for next week&lt;/h2&gt;
&lt;p&gt;We need to finish our MVP by the beginning of next week. We will also be presenting our MVP and video demos so we wil need to spend some time figuring out how to stream our demo to the class. After the MVP, we will continue working on improving hand gestures, if necessary, and we will begin working on the module component of the backend.&lt;/p&gt;

&lt;h2 id=&quot;upcoming-challenges&quot;&gt;Upcoming Challenges&lt;/h2&gt;
&lt;p&gt;We will be integrating our work that we have been doing independently by the beginning of next week, so it’s possible that this might be harder than we are anticipating. Currently, we are having one person record hand gestures that we are hoping will work for other members of the team, but it’s possible that the hand gesture might be too specific to the person recording it (however, this is why we allocated some time next week to improve the hand gestures if necessary).&lt;/p&gt;

&lt;h2 id=&quot;notes&quot;&gt;Notes&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=oJrAT8L4BrA&quot;&gt;Serializing and Saving Objects in Unity&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Fri, 01 May 2020 00:00:00 -0700</pubDate>
      </item>
    
      <item>
        <title>Blog 3: Bottom-Up</title>
        <link>/vrcapstone20sp-team3/2020/04/24/week3.html</link>
        <guid isPermaLink="true">/vrcapstone20sp-team3/2020/04/24/week3.html</guid>
        <description>&lt;p&gt;&lt;img src=&quot;/vrcapstone20sp-team3/assets/img/week3_collage.png&quot; alt=&quot;Collage showing progress in week 3&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;what-we-accomplished&quot;&gt;What we accomplished&lt;/h2&gt;
&lt;p&gt;We accomplished our goal of starting to implement hand tracking and the backend required for basic programming concepts. We got hand tracking to work by triggering an action (ie. create an object) when the user makes a specific pose with their hands. The backend supports block movement, emitting, and deletion through keyboard actions.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Logan: Researched and set up pose recognition for emit and block movement. Set up an emulated VR scene that allows us to develop features for hand tracking without building to the device every time, as this was a pain point for us.&lt;/li&gt;
  &lt;li&gt;Sea-Eun + Yuma: Pair programmed and began implementation on the backend Unity environment where users will be programming. Wrote initial code to emit, move, and delete blocks.&lt;/li&gt;
  &lt;li&gt;Erik: Researched and set up pose recognition for an initial looping attempt.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;plan-for-next-week&quot;&gt;Plan for next week&lt;/h2&gt;
&lt;p&gt;We would like to have most of our MVP finished by the end of next week. This involves polishing up the backend and finalizing on the specific poses we are using for hand recognition. We also need to extend pose recognition to detect movement as well (ie. user make a pose with their index finger and then moves their hand in a certain direction to denote which direction they want the block to move in). We are aiming to merge all components together into a single repository to combine the efforts that we did this week. We also need to make some final design decisions about what the environment will look like for the MVP (ie. where the blocks will be constrained to, theme, etc.)&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Logan + Erik: Finish pose and gesture recognition for block movement, emit, looping, and defining modules.&lt;/li&gt;
  &lt;li&gt;Sea-Eun + Yuma: Finish backend that supports block movement, emit, looping, and defining modules.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;notes&quot;&gt;Notes&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=lBzwUKQ3tbw&quot;&gt;Hand Tracking Gesture Detection Oculus Tutorial&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/jorgejgnz/HandTrackingGestureRecorder&quot;&gt;Hand Gesture Recorder Using Oculus Link&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://frl.nyu.edu/write-data-locally-on-oculus-quest/ &quot;&gt;Writing Data Locally on Oculus Quest&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://support.oculus.com/2255729571307786/?locale=en_US&quot;&gt;Transfering Data From Computer to Oculus Quest&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Fri, 24 Apr 2020 00:00:00 -0700</pubDate>
      </item>
    
      <item>
        <title>Blog 2: Strategy</title>
        <link>/vrcapstone20sp-team3/2020/04/17/week2.html</link>
        <guid isPermaLink="true">/vrcapstone20sp-team3/2020/04/17/week2.html</guid>
        <description>&lt;h2 id=&quot;what-we-accomplished&quot;&gt;What we accomplished&lt;/h2&gt;
&lt;p&gt;This week we researched and experimented with some of the available assets for Oculus hand tracking.  We found some examples of how others have done custom hand tracking (see notes) and we plan to use this as a starting point as we start developing our custom hand gestures. We finalized our project details and presented the project pitch in class on Tuesday and received some final feedback from the course staff about our idea. We also finished our detailed PRD, where we set milestones and outlined responsibilities for each member moving forward.&lt;/p&gt;

&lt;h2 id=&quot;plan-for-next-week&quot;&gt;Plan for next week&lt;/h2&gt;
&lt;p&gt;Start implementing our components! Our goal for next week is to have some working components that we can show the course staff during our lab session next week. Yuma and Sea-Eun will begin some work on the backend for the programming concepts we’re planning to implement. Logan will be working on implementing the hand gestures for block movement and the emit gesture, Erik will work on hand gestures for the define module and looping gesture. We aren’t necessarily planning on connecting all of this together yet (ie. maybe the backend components are tested with a controller, and then we add the custom hand gestures the week after).&lt;/p&gt;

&lt;h2 id=&quot;notes&quot;&gt;Notes&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/jorgejgnz/HandTrackingPack-HapticFeedback/&quot;&gt;Custom Hand Tracking Example&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.google.com/document/d/1-uIjydR_zQL7k6IQ9gUN79jNO5Kdd8oCZtkQjxiXoGc/edit&quot;&gt;Finalized PRD&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Fri, 17 Apr 2020 00:00:00 -0700</pubDate>
      </item>
    
      <item>
        <title>Blog 1: Ideation</title>
        <link>/vrcapstone20sp-team3/2020/04/10/week1.html</link>
        <guid isPermaLink="true">/vrcapstone20sp-team3/2020/04/10/week1.html</guid>
        <description>&lt;h2 id=&quot;what-we-accomplished&quot;&gt;What we accomplished&lt;/h2&gt;
&lt;p&gt;This week we spent a lot of time thinking about and iterating on our design. The team all met each other and we initially decided on pursuing a project called Symbolia which focused on allowing the user to evaluate math expressions and simple programming concepts by allowing the user to draw these in 3D space. We spent a pretty significant amount of time thinking about what project to pursue before deciding on this one, and we created a website and various pieces of concept art for Symbolia, since we thought that this work was due on Thursday. On Thursday, the course staff did not like our idea so we had to start from scratch. We spent a significant amount of time on Thursday and Friday thinking about ideas and how the implementation would look like and we eventually settled on trying to focus on somehwat novel hand tracking technology to teach a user programming concepts.&lt;/p&gt;

&lt;p&gt;The project that we decided to pursue is called Blockly, which is an environment where users can learn how to program by introducing various ways that a user can perform fundamental programming concepts (ie. looping, variable assignment, etc) using hand motions to control a block. We spent a good amount of time on Saturday redoing our work to create a brand new website, concept art, a video, and this blog post! We still need to work out a few aspects of our design, but we feel fairly confident about the main ideas.&lt;/p&gt;

&lt;h2 id=&quot;plan-for-next-week&quot;&gt;Plan for next week&lt;/h2&gt;
&lt;p&gt;Our main goal for next week will be to really hammer down on the exact specifics of how users will learn programming from our system (ie. what is the user interface, what exact hand commands should correspond to which programming concepts). Our deliverable will be a finished PRD that will give us a good plan moving forward. We hope to get our environments all set up for programming in Unity and by the end of the week (ie. after we finish our PRD) we want to be ready to start implementing a prototype a prototype.&lt;/p&gt;

&lt;h2 id=&quot;notes&quot;&gt;Notes&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Project idea notes: &lt;a href=&quot;https://docs.google.com/document/d/14HqkGo25-KkSJPUrV5kkn3qtYqYhWiz3rqzr2RcS-js/edit?ts=5e8cf990&quot;&gt;google doc&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Fri, 10 Apr 2020 00:00:00 -0700</pubDate>
      </item>
    
  </channel>
</rss>
